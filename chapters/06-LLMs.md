# LLM ها

تو بخش های قبلی چند بار اسم AI coding agent و AI assistant رو‌ آوردم. اینا چه ربطی دارن به LLM؟
یه AI agent ای مثل cursor, یه نرم افزاره که توی قسمت چتش میتونیم LLM های مختلفی رو انتخاب کنیم و ازشون استفاده کنیم.

### مدل زبانی بزرگ یا LLM

مدل زبانی بزرگ یا LLM مخفف Large Language Model هست  
و LLM های مختلفی داریم که هر کدوم با دیتاهای متفاوت و اهداف خاصی آموزش دیدن.
بعضی ها به اختصار بهشون میگن مدل.

مثلاً **GPT-4o** و **Claude 3.5 Sonnet** در زمانی که این متن نوشته میشه، از بهترین LLMها برای تولید کد و کمک در برنامه‌نویسی هستن.  

اما برای اینکه **بیشترین بهره‌وری رو از LLMها بگیریم**، خیلی مهمه که ویژگی‌ها و محدودیت‌هاشون رو بدونیم.

###  دو تا مفهوم اصلی وجود داره که باید درک کنیم:

### 1. **زمینه (Context)**

کانتکست همون اطلاعاتیه که به LLM می‌دیم.  
مثلاً توضیح پروژه، کد قبلی، فایل‌های مرتبط، یا سوال‌هایی که مطرح کردیم.  
هرچی زمینه دقیق‌تر، کامل‌تر و مرتبط‌تر باشه، LLM می‌تونه جواب‌های بهتری بده.  
اگه فقط بپرسیم «این چرا ارور می‌ده؟» بدون اینکه ارور یا کد رو بدیم، طبیعیه که مدل هم گیج بشه!

**یه نکته مهم: LLMها حافظه دائمی ندارن (مگر اینکه توی یه سیستم مثل RAG یا Agent باشن).**

**محدودیت کانتکست یا Context Window**:
اکثرا بعد از چند وقت چت کردن با یه مدل, لیمیت کانتکست اش رو میزنیم.
یعنی چی؟

یعنی مدل فقط یه مقدار مشخصی از اطلاعات رو می‌تونه هم‌زمان توی حافظه‌ش نگه داره و بر اساس اون تصمیم بگیره. به این می‌گن **context window**.  
برای مدل‌های قوی مثل GPT-4.5 یا Claude Opus این پنجره می‌تونه تا حدود 200 تا 300 هزار توکن بره، ولی بازم محدوده.

وقتی از یه حدی بیشتر بشه، مدل شروع می‌کنه به فراموش کردن چیزهای اول چت، یا حتی فایل‌هایی که قبلاً خونده بوده.

### 2. **توکن (Token)**

وLLMها ورودی و خروجی رو به جای کلمات، به صورت واحدهای کوچکتری به اسم "توکن" پردازش می‌کنن.  
هر کلمه، علامت، فاصله یا حتی بخشی از یه کلمه می‌تونه یه توکن باشه.  
مثلاً کلمه `function` معمولاً یه توکنه، ولی `internationalization` ممکنه چند توکن بشه.

مدل‌ها بر اساس تعداد توکن‌هایی که می‌تونن توی یه پیام بخونن و جواب بدن، محدودیت دارن. مثلاً:
<div dir='rtl'>
- GPT-4o حدود **128K توکن** ظرفیت داره (تقریباً معادل 300 صفحه متن!)
<br>
- بعضی مدل‌های دیگه مثل GPT-3.5 فقط تا **16K یا 32K** رو ساپورت می‌کنن.
</div>
<br>
گاهی اوقات به دلیل اینکه کانتکست رو هندل نکردیم و لیمیتش رو میزنیم اتفاق های عجیبی میوفته, مثل:

### هذیان گویی یا Hallucination

وقتی AI داره مشخصا پرت و پلا میگه, به این پدیده می‌گن "**hallucination**" یا هذیون گفتن. یعنی یه چیزی رو از خودش درمیاره چون فکر می‌کنه جوابه درسته.  

***مثال:***
فرض کن یه پروژه React داریم و تو از مدل می‌پرسی:

> «این ارور `Cannot read properties of undefined (reading 'map')` یعنی چی؟»

مدل در جواب می‌گه:

> «این ارور معمولاً به این دلیله که `map` رو روی یک عدد یا رشته استفاده کردی. مثلاً اگه `const data = 42` باشه و بخوای `data.map(...)` بزنی.»

در حالی که کدت این بوده:

```js
const data = undefined;
data.map(item => ...)

```

#### نتیجه:

مدل تلاش می‌کنه یه چیزی سر هم کنه که منطقی به نظر بیاد، حتی اگه واقعیت نداشته باشه.


### چی باعث میشه LLM دچار hallucination بشه؟
<div dir="rtl">
1. Context ناقص یا ناکافی
<br>  
    وقتی توکن‌های ورودی خیلی کم باشن یا اطلاعات لازم به مدل داده نشه، مجبور میشه خودش حدس بزنه.  
    این حدس‌ها بعضی وقتا اشتباه در میان و مدل عملاً از خودش یه چیز در میاره.
<br>
<br>
2. Context بیش از حد / محدودیت توکن 
<br>  
    وقتی تعداد توکن‌ها خیلی زیاد بشه، ممکنه مدل نتونه کل context رو درست پردازش کنه (مثلاً از اولش چیزهایی یادش بره).  
    تو بعضی مدل‌ها، وقتی نزدیک سقف توکن می‌ری، مدل فقط روی آخرین بخش‌ها تمرکز می‌کنه و قسمت‌های مهم قبلی رو نادیده می‌گیره. این باعث میشه جواب‌ها بی‌ربط یا اشتباه بشن.
<br>
<br>
3. موضوعات تخصصی یا خارج از دامنه آموزش مدل
<br>  
    بعضی وقتا مدل راجع‌به چیزی نظر می‌ده که اصلاً تو دیتای آموزشی‌ش نبوده یا خیلی محدود بوده. مثلاً درباره یه API خیلی جدید یا یه ابزار نایاب.
<br>
<br>
4. پرامپت‌های مبهم یا گمراه‌کننده  
<br> 
    اگه پرامپتت خیلی کلی، مبهم، یا چندپهلو باشه، مدل نمی‌فهمه دقیقاً چی می‌خوای و برای اینکه "مفید" باشه،  یه چیزی می‌سازه.
</div>


### پس چی کار کنیم؟
<div dir="rtl">
- اطلاعات یا کانتکست کافی و دقیق و به اندازه بهش بدیم
<br>
- پرامپت واضح، مرحله به مرحله بنویسیم
<br>    
- بدونیم مدل چقدر context رو می‌تونه هندل کنه
<br>
- از مدل درست برای کاری مثل برنامه نویسی استفاده کنیم
</div>

<br>
حالا وقتشه فرق بین Prompt Engineering و Context Engineering رو درک کنیم.

---

*بخش ۷ ->[مهندسی کانتکست در مقابل مهندسی پرامپت](07-context-engineering-vs-prompt-engineering.md)* 
